---
title: "Literature Review"
author: "Chelsea Matthews"
date: "27 August 2019"
output: html_document
bibliography: bibliography.bib
---

To do: 
Explore strengths and weaknesses of main sequencing platforms. 
Work out a range of relatively common ways that people use this data to get a de-novo assembly.
Create a range of reproducible pipelines in snakemake or nextflow that use these methods for de-novo assembly. 
Benchmark these pipelines and the associated tools using another reproducible pipeline in snakemake or nextflow and a quality metric to show how long methods take and the quality of what you get out. 

Basically, find the 'best' way to get a desired outcome where best is optimising money and time. 

## Introduction

In 1953 the three-dimensional structure of DNA was solved by Watson and Crick [@watson_1953] but the next step, sequencing the order of nucleic acids, proved not to be trivial and it wasn't until 1977 that Sanger, Nickeln and Coulson published their gamechanging paper "DNA sequencing with chain-terminating inhibitors" [@sanger_1977]. While this wasn't the first sequencing technique developed, it was robust, easy to use and accurate and became the most common methodology for DNA sequencing in the following years [@heather_2016]. This method, commonly called Sanger sequencing, is based on the chain termination method. By using DNA Polymerase to synthesise the complementary strand of a single-stranded DNA molecule in the presence of a small number of chain-terminating dideoxynucleotides, double stranded fragments terminating at various different lengths are obtained. Through fractioning these fragments with electrophoresis, the resulting bands give the sequence of nucleotides [@sanger_1977; @frana_2002]. By 1991, much progress had been made in automating some of these steps and hence, scientists were projecting being able to sequence up to 1Mb per year in the very near future and, with further improvements in methodology and computing capability, up to 100Mb per year in the next 5 to 10 years [hunkapiller_1991]. Sanger sequencing, **being 99.99%** accurate, was considered the gold standard for confirmation of variants in medical diagnoses for many years [beck_2016]. 

## Second Generation - pyrosequencing

The second generation of sequencing technology began to emerge around the same time that large-scale chain-termination methods were being developed [@heather_2016] and was characterised by the use of a luminescent method **for inferring pyrophosphate production as each nucleotide is washed over the template DNA**.  

## Third Generation - PacBio and Nanopore

The third generation of sequencing technologies is generally characterised by the ability to sequence single molecules, negating the need for PCR steps.

Sequencing Platforms and error profiles/types. Strengths, weaknesses. Recommended coverage. (Maybe make a table summarising this information)

## Fourth Generation

The most recent major advance in the field of sequencing technology is Circular Consensus Sequencing (CCS) from PacBio where a highly accurate consensus sequence is derived from multiple passes around a single molecule [@wenger_2019] **(see Figure ??)**. This technology requires 


Sequencing Platforms and error profiles/types. Strengths, weaknesses. Recommended coverage. (Maybe make a table summarising this information)

For nanopore, discuss basecalling. 

Assembly tools and algorithms that deal with each type of data. 
Long, high quality reads. 
short reads, high quality (paired end. Maybe mention HiC here?)
PacBio and nanopore reads. 
PacBio HiFi reads
   
How much data will you get from a particular platform. 

What about quality trimming? How much do you lose?

Discuss algorithms (sorted by algorithm type) and refer back to the different types of sequencing. 

Problems with assembly? What can go wrong? How do the limitations of the sequencing platforms and assembly tools transfer into sequencing errors? 

Genome assembly quality (with and without a reference).
With a reference
-Quast
        
Without a reference. Explain why this is more difficult. 
- N50
- BUSCO score
- LTR Retrotransposons (particularly for plants?)

### Conclusion
Many authors have investigated the differences in genome quality and CPU hours between a range of different assembly tools/algorithms while others focus more on ???. Nowhere is there a single resource that informs a bioinformatician of the pros and cons at every decision along the way of generating a de-novo assembly which is supported by rigorous benchmarking and the provision of reproducible pipelines. 


```{r}
#list of languages embedded by knitr into r
names(knitr::knit_engines$get())

```

For example, python can be used. 

```{python, engine.path = '/home/chelsea/anaconda3/bin/python3'}
# Above code enables python version 3
import sys
print(sys.version)
```

Review quality trimming tools

Review tools based on algorithms used. 


## References


